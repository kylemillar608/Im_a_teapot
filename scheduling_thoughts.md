# Scheduling Paradigms
## Intro
A problem that has recently become a sore point for my team is that of delayed task execution. A question like, "How can we make these processes run 15 days from now?" becomes a long debate more and more consistently with each passing week. More specifically, we are debating between processing these delayed tasks in real-time or in batches. The approaches are similar, but the systems that emerge from them are very different.
## What problem are we trying to solve?
We have a collection of kubernetes-hosted microservices that allow for the recurring billing of insurance premiums. On top of that, we send out communications to customers to track certain lifecycle events that happen along the way. This is only a small part of our business processes, but already you can see why scheduling becomes so important. How can we bill customers monthly? Yearly? What about if a payment fails? Should we retry that payment every 3 days or should we try to time the retries on the days that get the least failures? Additionally, what if we need to send reminders for the customer to pay? All of our invoicing services boil down to payment/customer communication functions and the timing logic around them. Since we are using microservices and the dates are potentially months away, there are a few requirements that arise (amongst others).
	1. Solution must be reusable by all microservices
	2. Delayed tasks must be persisted
	3. Highly scalable
	4. Controllable - should be able to retrieve/update/start/pause/resume/cancel jobs
  5. Easily monitored
## Real-time vs. Batch
The problem of scheduling can be solved with an infinite amount of implementations. However, any of these implementations is going to be categorized into one of two categories - real-time or batch processing. Although, in implementation, they are actually very similar. 

In real-time processing, each individual task will be scheduled and processed independently as its schedule expires. For example, if I need to charge a customer in a month, I will schedule a charge task for 30 days from now. 30 days later, a process that is continuously polling for expired tasks (call it the scheduler), will pick up this task and notify some system that a charge is ready to be processed. It may happen that multiple customers are supposed to be charged at the same time, so the scheduler will just send out multiple events. 

In batch processing, the system will poll for tasks that are expired less frequently. It will process the tasks (or notify other systems that the tasks need to be processed) in batches. Sometimes that is small batches more frequently and sometimes that is big batches less frequently. Taking the customer charging example again, we will schedule a charge to be processed in 30 days. There will be a scheduler that polls the database every hour to look for expired charges, and each hour, it will attempt to process all of the charges that are expired. Both systems pick up all eligible records (up until some batch limit) from a data store and process them. The two approaches are the exact same except for the polling frequency and batch sizes. The real-time system processes very small batches continuously, whereas the batching system processes large batches infrequently. Which one is better?

There is a universally increasing desire to deliver results in real-time. If you've watched any football, you've seen commercials like this - Christian McCaffrey spills his secrets on a play with Next Gen Stats, Powered by AWS 

The advantages of real-time systems are undeniable. Would you rather your business/sales/marketing team to have data that is hour(s) old or exactly up-to-date? Would you rather be able to make predictions within the range of seconds or hours? Real-time is a clear winner over batch in terms of powering a business. 

Let's think of another aspect of the argument - the complexity of managing these systems. With a real-time scheduler, once it is in place, the batch size and polling frequency are not things that the average team member has to worry about. They are merely tuning mechanisms to increase efficiency and performance. (More on this performance will be discussed below) With a batch-based system, the batch size and polling frequency are everything. All those who are close to the scheduling system will be wary of the batch size and polling frequency. In the charging example, no one knows that in the real-time system 50 charges are pulled from the database at once every 30 seconds and continuously from then on after until there are no charges to be processed. All they know is that charging is happening continuously and on-time (and predictably). For a batch-based system, everyone becomes aware that "that charge will not be processed for another hour, with the next batch" or "we need to increase the batch size so we can process all the charges in the SLA". The configurations of the system become well-known disadvantages in the process. And the issues propagate to your downstream applications if you are calling any API's. Downstream systems will thank you when you shift from calling their API frantically for 10 minutes followed by radio silence for an hour. 

In fact, batch-based systems are, by definition, less consistent than real-time systems. And, everyone wants their system to work consistently and predictably. In batch systems, for 90% of an hour, the services are sitting idle, but for 10% of the hour, they are blasted mercilessly until the batch is completed. Anyone with experience with these types of systems will be familiar with the constant struggle of configuring the system to utilize as much of the batch window as possible, but not let it get too close to the other batch, because if batches overlap, bad things will happen and quickly. Either you put a locking/unlocking mechanism to synchronize batches or else your batches will overlap, potentially causing massive amounts of duplicates, and definitely putting undue stress on the system. In my team's experience, both. Back to the inconsistency, the performance of a system with such contrasting behavior is difficult to assess. One, how do you allocate resources to your servers when 90% of the time they are idle or running at much lower utilization? Two, even with low CPU/memory allocation and horizonal scaling, it can be difficult to understand the health of your system when it is consistently producing alarms at the start of batches, when services are not scaled. There are ways around this, but it becomes more complex and there is a significant amount of planning to be done based on your batch times. Three, the performance of a system that sprints 10% of the time and sleeps the remaining 90% is never going to be as performant as one that jogs at a nice, safe, and efficient 60% CPU 100% of the time. A classic tortoise vs. hare scenario.
## Downsides of a real-time system
There is a reason everyone does not do there scheduling in real-time. It is because the real-time systems are more complex in terms of initial development efforts. Although batch-based systems are complex in their own right, it is much easier to get "something" out the door. The complexities (some mentioned in the last section) arise later on. With real-time systems, there must be an investment put into threading logic, retry logic, clustering, potentially sharding, and more before you can have any type of working, scalable scheduling system. That thought alone will stop many teams. Luckily, there are some libraries out there that do the work for you (Quartz for Java and Bull for Node). Unfortunately, the options are very limited. If they do not fit your use case, it very well may be that creating your own implementation is not worth it.
## Independent service v. Integrated
In microservices, there is a desire to have each microservice do what it is responsible for and only that. In coding, there is a principle called DRY ("Don't Repeat Yourself"). Microservices and DRY combat with each other nearly constantly. Designing scheduling mechanisms is no exception. Would you rather have a scheduling system that can be used regardless of whether it is being used to schedule payments or communications, or would you rather the communications and payments microservices handle that logic individually? If your scheduling logic is a key component to your business and has any complexity, repeating this logic across multiple disparate microservices does not make sense. Why would you want to integrate it into each microservice when you can create an isolated service for it? 

If you are implementing a custom, real-time solution it should be clear based on some of the requirements mentioned above that this work cannot be repeated across multiple services. It also becomes inefficient to repeat the logic of a batch-based system once it becomes more mature. You will need to expose functionality to configure and control the batches, implement a locking/unlocking mechanism to ensure jobs do not overlap, as well as potentially logic for pausing/resuming/cancelling/starting jobs. With any robustness/complexity in your scheduling requirements, a need for an isolated service becomes undeniable. Additionally, with the logic living in disparate services it becomes more likely that the scheduling logic will not be decoupled from the business logic, locking you into a place where the scheduler cannot be reused or abstracted later without significant efforts. For example, the implementation of a charging batch job could be that every hour all invoices that are unpaid are to be charged. Obviously, that same batch job logic cannot be applied to sending customer communications.
## A Solution for Everyone
According to the four categories of scheduling that I have discussed so far, there are four approaches to the solution - batch-based and integrated, batch-based and isolated, real-time and integrated, real-time and isolated.
 
Batch-based and integrated would be the easiest way to get a simple scheduling system out, but as soon as the system requires more features like exposing job controllability and configurability, it is not efficient to repeat this work across services. Not to mention it does not have the advantages of real-time processing. 

The batch-based and isolated solution is better, but it is inherently worse than the real-time and isolated solution. Both will require the same types of development work - abstraction for tasks/batches, polling mechanism, clustering, retry logic, etc. Why put the up-front cost into creating a scheduling service that is batch-based when the real-time solution will give much improved functionality? The real-time system will scale better, provide more precise data, and be less complex to manage once it is up and running. 

For the real-time and integrated approach, it would not be worth it in the case of creating your own custom implementation of a real-time scheduler, but when using a library, it may be more enticing. However, just like with the batch-based and integrated solution, it is not a good solution if you will need to expose functionality such as cancelling or starting tasks on-demand. Why create these API's across different services?

That leaves us with one best approach to the solution: isolated and real-time. With a little bit of up-front development cost, we can have a feature-rich system that can be applied to a myriad of problems. It is highly-scalable, configurable, and controllable. Also, it will be performant and consistent. We can look at our requirements and see that it checks all the boxes (and the others don’t.)

Requirements	Batch, Integrated	Batch, Isolated	Real-time, Integrated	Real-time, Isolated
Reusable		X		X
Persisted	X	X	X	X
Scalable			X	X
Controllable		X		X
Monitorable			Redundant monitors	X

***fix formatting
***update from isolated to independent
***Adjust requirements to match original article and organize to fit that pattern
***Add more examples, references, diagrams
***Try to prove myself wrong
***Consolidate
***Revise and revise again
